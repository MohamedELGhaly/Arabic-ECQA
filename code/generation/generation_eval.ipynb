{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FJo32IVxKXsn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting semantic-text-similarity\n",
            "  Using cached https://files.pythonhosted.org/packages/f1/d7/eade8afd89103e3dcc4b4db146a134a26bd7336ba86d9a95cf0d0e3a28cb/semantic_text_similarity-1.0.3-py3-none-any.whl\n",
            "Collecting pytorch-transformers==1.1.0 (from semantic-text-similarity)\n",
            "  Using cached https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl\n",
            "Collecting strsim (from semantic-text-similarity)\n",
            "  Using cached https://files.pythonhosted.org/packages/0d/95/14e5dea00c3bc73e5962261442957ee3691de8d51c97909ba7b2f46bf584/strsim-0.0.3-py3-none-any.whl\n",
            "Collecting fuzzywuzzy[speedup] (from semantic-text-similarity)\n",
            "  Using cached https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /home/ghaly/anaconda3/lib/python3.7/site-packages (from semantic-text-similarity) (1.4.1)\n",
            "Collecting torch (from semantic-text-similarity)\n",
            "  Using cached https://files.pythonhosted.org/packages/00/86/77a9eddbf46f1bca2468d16a401911f58917f95b63402d6a7a4522521e5d/torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Collecting regex (from pytorch-transformers==1.1.0->semantic-text-similarity)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/f2/20be658beb9ebef677550be562eae86c5433119b4b2fdb67035e9a841b0f/regex-2022.10.31-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (676kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 521kB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy in /home/ghaly/anaconda3/lib/python3.7/site-packages (from pytorch-transformers==1.1.0->semantic-text-similarity) (1.16.4)\n",
            "Requirement already satisfied: sentencepiece in /home/ghaly/anaconda3/lib/python3.7/site-packages (from pytorch-transformers==1.1.0->semantic-text-similarity) (0.1.83)\n",
            "Requirement already satisfied: tqdm in /home/ghaly/anaconda3/lib/python3.7/site-packages (from pytorch-transformers==1.1.0->semantic-text-similarity) (4.32.1)\n",
            "Requirement already satisfied: boto3 in /home/ghaly/anaconda3/lib/python3.7/site-packages (from pytorch-transformers==1.1.0->semantic-text-similarity) (1.9.225)\n",
            "Requirement already satisfied: requests in /home/ghaly/anaconda3/lib/python3.7/site-packages (from pytorch-transformers==1.1.0->semantic-text-similarity) (2.22.0)\n",
            "Collecting python-levenshtein>=0.12; extra == \"speedup\" (from fuzzywuzzy[speedup]->semantic-text-similarity)\n",
            "  Using cached https://files.pythonhosted.org/packages/c9/bd/fef1536c7ea8d22305c6d54fecf4e7abfc5b4b55782ff9193cdcea4ff8b9/python_Levenshtein-0.20.9-py3-none-any.whl\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" (from torch->semantic-text-similarity)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/41/fdeb62b5437996e841d83d7d2714ca75b886547ee8017ee2fe6ea409d983/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1MB 981kB/s eta 0:00:01     |███████████                     | 108.2MB 113kB/s eta 0:30:36     |███████████████████████▊        | 235.2MB 1.1MB/s eta 0:01:14     |█████████████████████████▋      | 253.9MB 525kB/s eta 0:02:01\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" (from torch->semantic-text-similarity)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/25/922c5996aada6611b79b53985af7999fc629aee1d5d001b6a22431e18fec/nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0MB 522kB/s eta 0:00:01\n",
            "\u001b[?25hCollecting typing-extensions (from torch->semantic-text-similarity)\n",
            "  Using cached https://files.pythonhosted.org/packages/0b/8e/f1a0a5a76cfef77e1eb6004cb49e5f8d72634da638420b9ea492ce8305e8/typing_extensions-4.4.0-py3-none-any.whl\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" (from torch->semantic-text-similarity)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/92/89cf558b514125d2ebd8344dd2f0533404b416486ff681d5434a5832a019/nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849kB)\n",
            "\u001b[K     |████████████████████████████████| 849kB 92kB/s eta 0:00:014\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" (from torch->semantic-text-similarity)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/30/66d4347d6e864334da5bb1c7571305e501dcb11b9155971421bb7bb5315f/nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1MB 78kB/s  eta 0:00:015     |█████████████▉                  | 240.5MB 947kB/s eta 0:05:35     |██████████████████▎             | 317.8MB 908kB/s eta 0:04:24     |██████████████████████████▊     | 466.0MB 1.0MB/s eta 0:01:29\n",
            "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ghaly/anaconda3/lib/python3.7/site-packages (from boto3->pytorch-transformers==1.1.0->semantic-text-similarity) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ghaly/anaconda3/lib/python3.7/site-packages (from boto3->pytorch-transformers==1.1.0->semantic-text-similarity) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.225 in /home/ghaly/anaconda3/lib/python3.7/site-packages (from boto3->pytorch-transformers==1.1.0->semantic-text-similarity) (1.12.225)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ghaly/anaconda3/lib/python3.7/site-packages (from requests->pytorch-transformers==1.1.0->semantic-text-similarity) (1.24.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /home/ghaly/anaconda3/lib/python3.7/site-packages (from requests->pytorch-transformers==1.1.0->semantic-text-similarity) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ghaly/anaconda3/lib/python3.7/site-packages (from requests->pytorch-transformers==1.1.0->semantic-text-similarity) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ghaly/anaconda3/lib/python3.7/site-packages (from requests->pytorch-transformers==1.1.0->semantic-text-similarity) (2019.6.16)\n",
            "Collecting Levenshtein==0.20.9 (from python-levenshtein>=0.12; extra == \"speedup\"->fuzzywuzzy[speedup]->semantic-text-similarity)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/ea/b2c2c26477111be2938dca870044583f6e785d952c0c424c7ccf0dbe0144/Levenshtein-0.20.9.tar.gz (122kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 950kB/s eta 0:00:01\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ghaly/anaconda3/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 178, in main\n",
            "    status = self.run(options, args)\n",
            "  File \"/home/ghaly/anaconda3/lib/python3.7/site-packages/pip/_internal/commands/install.py\", line 352, in run\n",
            "    resolver.resolve(requirement_set)\n",
            "  File \"/home/ghaly/anaconda3/lib/python3.7/site-packages/pip/_internal/resolve.py\", line 131, in resolve\n",
            "    self._resolve_one(requirement_set, req)\n",
            "  File \"/home/ghaly/anaconda3/lib/python3.7/site-packages/pip/_internal/resolve.py\", line 294, in _resolve_one\n",
            "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
            "  File \"/home/ghaly/anaconda3/lib/python3.7/site-packages/pip/_internal/resolve.py\", line 242, in _get_abstract_dist_for\n",
            "    self.require_hashes\n",
            "  File \"/home/ghaly/anaconda3/lib/python3.7/site-packages/pip/_internal/operations/prepare.py\", line 362, in prepare_linked_requirement\n",
            "    abstract_dist.prep_for_dist(finder, self.build_isolation)\n",
            "  File \"/home/ghaly/anaconda3/lib/python3.7/site-packages/pip/_internal/operations/prepare.py\", line 169, in prep_for_dist\n",
            "    self.install_backend_dependencies(finder=finder)\n",
            "  File \"/home/ghaly/anaconda3/lib/python3.7/site-packages/pip/_internal/operations/prepare.py\", line 123, in install_backend_dependencies\n",
            "    reqs = req.pep517_backend.get_requires_for_build_wheel()\n",
            "  File \"/home/ghaly/anaconda3/lib/python3.7/site-packages/pip/_vendor/pep517/wrappers.py\", line 71, in get_requires_for_build_wheel\n",
            "    'config_settings': config_settings\n",
            "  File \"/home/ghaly/anaconda3/lib/python3.7/site-packages/pip/_vendor/pep517/wrappers.py\", line 162, in _call_hook\n",
            "    raise BackendUnavailable\n",
            "pip._vendor.pep517.wrappers.BackendUnavailable\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install semantic-text-similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YsTkfvnmKeWB"
      },
      "outputs": [],
      "source": [
        "from semantic_text_similarity.models import WebBertSimilarity\n",
        "from semantic_text_similarity.models import ClinicalBertSimilarity\n",
        "\n",
        "web_model = WebBertSimilarity(device='cuda',batch_size=10) #defaults to GPU prediction\n",
        "\n",
        "# clinical_model = ClinicalBertSimilarity(device='cuda', batch_size=10) #defaults to GPU prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nxCHMEgBKhGi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pdb\n",
        "import json\n",
        "class GFG: \n",
        "  def __init__(self,graph): \n",
        "    self.graph = graph \n",
        "    self.ppl = len(graph) \n",
        "    self.jobs = len(graph[0]) \n",
        "\n",
        "  def bpm(self, u, matchR, seen): \n",
        "    for v in range(self.jobs):  \n",
        "      if self.graph[u][v] and seen[v] == False: \n",
        "        seen[v] = True\n",
        "        if matchR[v] == -1 or self.bpm(matchR[v], matchR, seen): \n",
        "          matchR[v] = u \n",
        "          return True\n",
        "    return False\n",
        "  \n",
        "  # Returns maximum number of matching \n",
        "  def maxBPM(self):\n",
        "    matchR = [-1] * self.jobs \n",
        "\n",
        "    result = 0\n",
        "    for i in range(self.ppl):\n",
        "      seen = [False] * self.jobs\n",
        "      if self.bpm(i, matchR, seen): \n",
        "        result += 1\n",
        "    return result, matchR\n",
        "\n",
        "def my_lcs(string, sub):\n",
        "  if(len(string)<= len(sub)):\n",
        "    sub, string = string, sub\n",
        "\n",
        "    lengths = [[0 for i in range(0,len(sub)+1)] for j in range(0,len(string)+1)]\n",
        "\n",
        "    for j in range(1,len(sub)+1):\n",
        "      for i in range(1,len(string)+1):\n",
        "        if (string[i-1] == sub[j-1]):\n",
        "          lengths[i][j] = lengths[i-1][j-1] + 1\n",
        "        else:\n",
        "          lengths[i][j] = max(lengths[i-1][j] , lengths[i][j-1])\n",
        "\n",
        "    return lengths[len(string)][len(sub)]\n",
        "\n",
        "class Rouge():\n",
        "  def __init__(self):\n",
        "    self.beta = 1.2\n",
        "\n",
        "  def calc_score(self, candidate, refs):\n",
        "    assert(len(candidate)==1)\t\n",
        "    assert(len(refs)>0)         \n",
        "    prec = []\n",
        "    rec = []\n",
        "\n",
        "  # split into tokens\n",
        "    token_c = candidate[0].split(\" \")\n",
        "    \t\n",
        "    for reference in refs:\n",
        "      # split into tokens\n",
        "      token_r = reference.split(\" \")\n",
        "      # compute the longest common subsequence\n",
        "      lcs = my_lcs(token_r, token_c)\n",
        "      if (lcs == None):\n",
        "        prec.append(0)\n",
        "        rec.append(0)\n",
        "      else:\n",
        "        prec.append(lcs/float(len(token_c)))\n",
        "        rec.append(lcs/float(len(token_r)))\n",
        "\n",
        "      prec_max = max(prec)\n",
        "      rec_max = max(rec)\n",
        "\n",
        "      if (prec_max!=0 and rec_max !=0):\n",
        "        score = ((1 + self.beta**2)*prec_max*rec_max)/float(rec_max + self.beta**2*prec_max)\n",
        "      else:\n",
        "        score = 0.0\n",
        "      return score\n",
        "\n",
        "  def compute_score(self, refs, test):\n",
        "    score = []\n",
        "    for i in range(len(refs)):\n",
        "      hypo = test[i]\n",
        "      ref = refs[i]\n",
        "      if (hypo == \" \" or hypo == \"\"):\n",
        "        score.append(0)\n",
        "      else:\n",
        "        score.append(self.calc_score([hypo], [ref]))\n",
        "    \n",
        "    average_score = np.mean(np.array(score))\n",
        "    return average_score, np.array(score)\n",
        "\n",
        "  def method(self):\n",
        "    return \"Rouge\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaH9bWlv13Dq"
      },
      "source": [
        "For evaluation of property generation models XGP and XGP-W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bNIt698VKi1W"
      },
      "outputs": [],
      "source": [
        "f = open('/home/ghaly/thesis/notebook/Commonsense Reasoning/Arabic-ECQA/Arabic-generation-author-split/text-generation/gpt2_props_output2.json')\n",
        "data = json.load(f)\n",
        "name = 'gpt2_props_output'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fLzLpT5eKl9H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: all CUDA-capable devices are busy or unavailable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b05b6b187899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0msts_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0mbipartite_graph_double\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msts_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msts_score\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msts_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/GPT-2/lib/python3.6/site-packages/semantic_text_similarity/models/bert/similarity.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, additional_features, return_predictions)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/GPT-2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m~/anaconda3/envs/GPT-2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/GPT-2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/GPT-2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/GPT-2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/GPT-2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: all CUDA-capable devices are busy or unavailable"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "sts_predictions_array = []\n",
        "sts_predictions_array2 = []\n",
        "positive_indices = []\n",
        "negative_indices = []\n",
        "sts_recall = 0.0\n",
        "sts_precision = 0.0\n",
        "sts_fscore = 0.0\n",
        "count = 0\n",
        "sts_threshold = 3\n",
        "\n",
        "counter = []\n",
        "for k in range(len(data[\"Input\"])):\n",
        "  if (k % 500 == 0):\n",
        "    print(k)\n",
        "  l1 = data[\"Gold\"][k]\n",
        "  l2 = data[\"Output\"][k]\n",
        "  if data[\"Correctness\"][k]:\n",
        "    positive_indices.append(k)\n",
        "    # l2 = data[\"Output\"][k]\n",
        "  else:\n",
        "    negative_indices.append(k)\n",
        "    # l2 = [data[\"Output\"][k][0]]\n",
        "  bipartite_graph = np.zeros((len(l1), len(l2)))\n",
        "  bipartite_graph_double = np.zeros((len(l1), len(l2)))\n",
        "  \n",
        "  for i in range(len(l1)):\n",
        "    for j in range(len(l2)):\n",
        "      sts_score = web_model.predict([(l1[i], l2[j])])[0]\n",
        "      bipartite_graph_double[i][j] = sts_score\n",
        "      if (sts_score >= sts_threshold):\n",
        "        bipartite_graph[i][j] = 1\n",
        "      else:\n",
        "        bipartite_graph[i][j] = 0\n",
        "\n",
        "  g = GFG(bipartite_graph_double) \n",
        "  number, division_list = g.maxBPM()\n",
        "\n",
        "  # property i will be matched with division_list[i]  change this comment\n",
        "  score0 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if(division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "\n",
        "    if (j != -1):\n",
        "      sts_score = bipartite_graph_double[i][j]\n",
        "      score0 += sts_score\n",
        "      count += 1\n",
        "      counter.append(count)\n",
        "      sts_predictions_array2.append(sts_score)\n",
        "      \n",
        "    else:\n",
        "      count += 1\n",
        "      sts_predictions_array2.append(0)\n",
        "\n",
        "  sts_predictions_array.append(score0/len(l1))\n",
        "\n",
        "  g = GFG(bipartite_graph) \n",
        "  number, division_list = g.maxBPM()\n",
        "\n",
        "  # property i will be matched with division_list[i]  change this comment\n",
        "  score_recall0 = 0\n",
        "  score_precision0 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if(division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "\n",
        "    if (j != -1):\n",
        "      score_recall0 += 1\n",
        "      score_precision0 += 1\n",
        "      count += 1\n",
        "    else:\n",
        "      count += 1\n",
        "  sts_recall += score_recall0/len(l1)\n",
        "  sts_precision += score_precision0/len(l2)\n",
        "  a0 = score_recall0/len(l1)\n",
        "  b0 = score_precision0/len(l2)\n",
        "  if (a0+b0 != 0):\n",
        "    sts_fscore += 2*a0*b0/(a0+b0)\n",
        "\n",
        "# print(count)\n",
        "# print(len(counter))\n",
        "x = len(data[\"Input\"])\n",
        "print(\"STS Score==============\")\n",
        "print(sts_recall/x)\n",
        "print(sts_precision/x)\n",
        "print(sts_fscore/x)\n",
        "# print(np.average(sts_predictions_array)/5)\n",
        "# predictions_positive = [sts_predictions_array[i] for i in positive_indices]\n",
        "# predictions_negative = [sts_predictions_array[i] for i in negative_indices]\n",
        "# print(np.average(predictions_positive)/5)\n",
        "# print(np.average(predictions_negative)/5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZdWAcEiK7gf"
      },
      "outputs": [],
      "source": [
        "spice_thresholder = []\n",
        "cider_refs_thresholder = []\n",
        "cider_test_thresholder = []\n",
        "count = 0\n",
        "for k in range(len(data[\"Input\"])):\n",
        "  # if (k % 500 == 0):\n",
        "  #   print(k)\n",
        "  l1 = data[\"Gold\"][k]\n",
        "  l2 = data[\"Output\"][k]\n",
        "  # correctness = data[\"Correctness\"][k]\n",
        "  # if not correctness:\n",
        "  #   l2 = [data[\"Output\"][k][0]]\n",
        "  # else:\n",
        "  #   l2 = data[\"Output\"][k]\n",
        "  for i in range(len(l1)):\n",
        "    for j in range(len(l2)):\n",
        "      struct = {\n",
        "          \"image_id\": count,\n",
        "          \"caption\": l2[j]\n",
        "      }\n",
        "      cider_test_thresholder.append(struct)\n",
        "      struct = {\n",
        "          \"image_id\": count,\n",
        "          \"caption\": l1[i]\n",
        "      }\n",
        "      cider_refs_thresholder.append(struct)\n",
        "      struct = {\n",
        "          \"image_id\": count,\n",
        "          \"test\": l2[j],\n",
        "          \"refs\": [l1[i]]\n",
        "      }\n",
        "      spice_thresholder.append(struct)\n",
        "      count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLVuDoBtLDLG"
      },
      "outputs": [],
      "source": [
        "%cd cider/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gqgl3piiK8Qp"
      },
      "outputs": [],
      "source": [
        "with open('./data/cider_' + name + '_refs.json', 'w') as outfile:\n",
        "    json.dump(cider_refs_thresholder, outfile)\n",
        "with open('./data/cider_' + name + '_test.json', 'w') as outfile:\n",
        "    json.dump(cider_test_thresholder, outfile)\n",
        "with open('../spice/spice_' + name + '.json', 'w') as outfile:\n",
        "    json.dump(spice_thresholder, outfile)\n",
        "\n",
        "params = {\n",
        "  \"pathToData\" : \"data/\",\n",
        "\t\"refName\" : 'cider_' + name + '_refs.json',\n",
        "\t\"candName\" : 'cider_' + name + '_test.json',\n",
        "\t\"resultFile\" : 'cider_' + name + '_results.json',\n",
        "\t\"idf\" : \"coco-val-df\"\n",
        "}\n",
        "with open('params.json', 'w') as outfile:\n",
        "    json.dump(params, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIqxxiUdLFaL"
      },
      "outputs": [],
      "source": [
        "!python2 cidereval.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMks1Ka-LIeb"
      },
      "outputs": [],
      "source": [
        "file2 = open('./cider_' + name + '_results.json')\n",
        "cider_output = json.load(file2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwGgq7OsLKI1"
      },
      "outputs": [],
      "source": [
        "%cd ../meteor/\n",
        "write_file = open(name + \"_meteor_refs\", \"w\")\n",
        "for i in range(len(cider_refs_thresholder)):\n",
        "  new_line = cider_refs_thresholder[i]['caption'].replace(\"\\n\", \" \") + \" \\n\"\n",
        "  write_file.write(new_line)\n",
        "write_file.close()\n",
        "\n",
        "write_file2 = open(name + \"_meteor_test\", \"w\")\n",
        "for i in range(len(cider_test_thresholder)):\n",
        "  if (cider_test_thresholder[i]['caption'] == \"\" or cider_test_thresholder[i]['caption'] == \" \"):\n",
        "    new_line = \"empty \\n\"\n",
        "  else:\n",
        "    new_line = cider_test_thresholder[i]['caption'].replace(\"\\n\", \" \") + \" \\n\"\n",
        "  write_file2.write(new_line)\n",
        "write_file2.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE1skD4XLOnt"
      },
      "outputs": [],
      "source": [
        "meteor_scores = !java -Xmx2G -jar meteor-1.5.jar ./gpt2_raw_output_meteor_test ./gpt2_raw_output_meteor_refs -l en -norm -a data/paraphrase-en.gz -q\n",
        "meteor_scores = [float(meteor_scores[i]) for i in range(len(meteor_scores))]\n",
        "meteor_scores[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W--0hehLQXT"
      },
      "outputs": [],
      "source": [
        "%cd ../spice/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzGsT2DgLUF1"
      },
      "outputs": [],
      "source": [
        "#in spice directory\n",
        "!java -Xmx8G -jar spice-1.0.jar spice_gpt2_raw_output.json -cache ./cache -out spice_gpt2_raw_output_output.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbOIAsnSLVH2"
      },
      "outputs": [],
      "source": [
        "file2 = open('./spice_' + name + '_output.json')\n",
        "spice_output = json.load(file2)\n",
        "len(spice_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DL1h96VLX-m"
      },
      "outputs": [],
      "source": [
        "rouge_test =  [cider_test_thresholder[i]['caption'] for i in range(len(cider_test_thresholder))]\n",
        "rouge_refs =  [cider_refs_thresholder[i]['caption'] for i in range(len(cider_refs_thresholder))]\n",
        "r = Rouge()\n",
        "rouge_scores = r.compute_score(rouge_refs, rouge_test)\n",
        "rouge_scores[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmKVN-gxLZqq"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "spice_recall = 0.0\n",
        "spice_precision = 0.0\n",
        "spice_fscore = 0.0\n",
        "cider_recall = 0.0\n",
        "cider_precision = 0.0\n",
        "cider_fscore = 0.0\n",
        "meteor_recall = 0.0\n",
        "meteor_precision = 0.0\n",
        "meteor_fscore = 0.0\n",
        "rouge_recall = 0.0\n",
        "rouge_precision = 0.0\n",
        "rouge_fscore = 0.0\n",
        "count1 = 0\n",
        "count = 0\n",
        "spice_threshold = 0.4\n",
        "cider_threshold = 3\n",
        "meteor_threshold = 0.3\n",
        "rouge_threshold = 0.3\n",
        "counter = []\n",
        "for k in range(len(data[\"Input\"])):\n",
        "  if (k % 500 == 0):\n",
        "    print(k)\n",
        "  l1 = data[\"Gold\"][k]\n",
        "  l2 = data[\"Output\"][k]\n",
        "  \n",
        "  bipartite_graph = np.zeros((len(l1), len(l2)))\n",
        "  bipartite_graph_double_spice = np.zeros((len(l1), len(l2)))\n",
        "  bipartite_graph_double_meteor = np.zeros((len(l1), len(l2)))\n",
        "  bipartite_graph_double_rouge = np.zeros((len(l1), len(l2)))\n",
        "  \n",
        "  for i in range(len(l1)):\n",
        "    for j in range(len(l2)):\n",
        "      cider_score = cider_output['CIDEr'][count1]\n",
        "      meteor_score = meteor_scores[count1]\n",
        "      rouge_score = rouge_scores[1][count1]\n",
        "      spice_score = spice_output[count1]['scores']['All']['f']\n",
        "      count1 += 1\n",
        "      if (spice_score >= spice_threshold):\n",
        "        bipartite_graph_double_spice[i][j] = 1\n",
        "      else:\n",
        "        bipartite_graph_double_spice[i][j] = 0\n",
        "      if (cider_score >= cider_threshold):\n",
        "        bipartite_graph[i][j] = 1\n",
        "      else:\n",
        "        bipartite_graph[i][j] = 0\n",
        "      if (meteor_score >= meteor_threshold):\n",
        "        bipartite_graph_double_meteor[i][j] = 1\n",
        "      else:\n",
        "        bipartite_graph_double_meteor[i][j] = 0\n",
        "      if (rouge_score >= rouge_threshold):\n",
        "        bipartite_graph_double_rouge[i][j] = 1\n",
        "      else:\n",
        "        bipartite_graph_double_rouge[i][j] = 0\n",
        "\n",
        "  g = GFG(bipartite_graph_double_spice)\n",
        "  number, division_list = g.maxBPM()\n",
        "  \n",
        "  score_recall1 = 0\n",
        "  score_precision1 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if (division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "    \n",
        "    if (j != -1):\n",
        "      score_recall1 += 1\n",
        "      score_precision1 += 1\n",
        "      count += 1\n",
        "    else:\n",
        "      count += 1\n",
        "\n",
        "  spice_recall += score_recall1/len(l1)\n",
        "  spice_precision += score_precision1/len(l2)\n",
        "  a1 = score_recall1/len(l1)\n",
        "  b1 = score_precision1/len(l2)\n",
        "  if (a1+b1 != 0):\n",
        "    spice_fscore += 2*a1*b1/(a1+b1)\n",
        "\n",
        "  g = GFG(bipartite_graph)\n",
        "  number, division_list = g.maxBPM()\n",
        "  \n",
        "  score_recall2 = 0\n",
        "  score_precision2 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if (division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "    \n",
        "    if (j != -1):\n",
        "      score_recall2 += 1\n",
        "      score_precision2 += 1\n",
        "      count += 1 \n",
        "    else:\n",
        "      count += 1\n",
        "\n",
        "  cider_recall += score_recall2/len(l1)\n",
        "  cider_precision += score_precision2/len(l2)\n",
        "  a2 = score_recall2/len(l1)\n",
        "  b2 = score_precision2/len(l2)\n",
        "  if (a2+b2 != 0):\n",
        "    cider_fscore += 2*a2*b2/(a2+b2)\n",
        "\n",
        "  g = GFG(bipartite_graph_double_meteor) \n",
        "  number, division_list = g.maxBPM()\n",
        "  \n",
        "  score_recall3 = 0\n",
        "  score_precision3 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if (division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "    if (j != -1):\n",
        "      score_recall3 += 1\n",
        "      score_precision3 += 1\n",
        "      count += 1 \n",
        "    else:\n",
        "      count += 1\n",
        "  meteor_recall += score_recall3/len(l1)\n",
        "  meteor_precision += score_precision3/len(l2)\n",
        "  a2 = score_recall3/len(l1)\n",
        "  b2 = score_precision3/len(l2)\n",
        "  if (a2+b2 != 0):\n",
        "    meteor_fscore += 2*a2*b2/(a2+b2)\n",
        "\n",
        "  g = GFG(bipartite_graph_double_rouge) \n",
        "  number, division_list = g.maxBPM()\n",
        "  \n",
        "  score_recall4 = 0\n",
        "  score_precision4 = 0\n",
        "  for i in range(len(l1)):\n",
        "    j = -1\n",
        "    for k in range(len(division_list)):\n",
        "      if (division_list[k] == i):\n",
        "        j = k\n",
        "        break\n",
        "    if (j != -1):\n",
        "      score_recall4 += 1\n",
        "      score_precision4 += 1\n",
        "      count += 1 \n",
        "    else:\n",
        "      count += 1\n",
        "  rouge_recall += score_recall4/len(l1)\n",
        "  rouge_precision += score_precision4/len(l2)\n",
        "  a2 = score_recall4/len(l1)\n",
        "  b2 = score_precision4/len(l2)\n",
        "  if (a2+b2 != 0):\n",
        "    rouge_fscore += 2*a2*b2/(a2+b2)\n",
        "\n",
        "x = len(data[\"Input\"])\n",
        "print(\"SPICE==============\")\n",
        "print(spice_recall/x)\n",
        "print(spice_precision/x)\n",
        "print(spice_fscore/x)\n",
        "print(\"CIDEr==============\")\n",
        "print(cider_recall/x)\n",
        "print(cider_precision/x)\n",
        "print(cider_fscore/x)\n",
        "print(\"METEOR==============\")\n",
        "print(meteor_recall/x)\n",
        "print(meteor_precision/x)\n",
        "print(meteor_fscore/x)\n",
        "print(\"ROUGE==============\")\n",
        "print(rouge_recall/x)\n",
        "print(rouge_precision/x)\n",
        "print(rouge_fscore/x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2opCekB50g1_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm-jKoiB1oR9"
      },
      "source": [
        "For evaluation of free-flow generation models XGF-I and XGF-II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o8mEghB0hOZ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "f = open('../GPT_Multiple_Output/gpt2_raw_freeflow_output.json')\n",
        "data = json.load(f)\n",
        "name = \"gpt2_raw_freeflow_output\"\n",
        "\n",
        "spice_thresholder = []\n",
        "cider_refs_thresholder = []\n",
        "cider_test_thresholder = []\n",
        "count = 0\n",
        "for k in range(len(data[\"input\"])):\n",
        "  # if (k % 500 == 0):\n",
        "  #   print(k)\n",
        "  l1 = data[\"gold\"][k].replace(\"<EOS>\",\"\")\n",
        "  l2 = data[\"output\"][k]\n",
        "  # l1 = gold[k]\n",
        "  # l2 = prime[k]\n",
        "  struct = {\n",
        "      \"image_id\": count,\n",
        "      \"caption\": l2\n",
        "      }\n",
        "  cider_test_thresholder.append(struct)\n",
        "  struct = {\n",
        "      \"image_id\": count,\n",
        "      \"caption\": l1\n",
        "  }\n",
        "  cider_refs_thresholder.append(struct)\n",
        "  struct = {\n",
        "      \"image_id\": count,\n",
        "      \"test\": l2,\n",
        "      \"refs\": [l1]\n",
        "  }\n",
        "  spice_thresholder.append(struct)\n",
        "  count += 1\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXxKDmAK0nW2"
      },
      "outputs": [],
      "source": [
        "%cd ../cider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtFfDIpN0yBb"
      },
      "outputs": [],
      "source": [
        "with open('./data/cider_' + name + '_refs.json', 'w') as outfile:\n",
        "    json.dump(cider_refs_thresholder, outfile)\n",
        "with open('./data/cider_' + name + '_test.json', 'w') as outfile:\n",
        "    json.dump(cider_test_thresholder, outfile)\n",
        "with open('../spice/spice_' + name + '.json', 'w') as outfile:\n",
        "    json.dump(spice_thresholder, outfile)\n",
        "\n",
        "params = {\n",
        "  \"pathToData\" : \"data/\",\n",
        "\t\"refName\" : 'cider_' + name + '_refs.json',\n",
        "\t\"candName\" : 'cider_' + name + '_test.json',\n",
        "\t\"resultFile\" : 'cider_' + name + '_results.json',\n",
        "\t\"idf\" : \"coco-val-df\"\n",
        "}\n",
        "with open('params.json', 'w') as outfile:\n",
        "    json.dump(params, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSbG7viB02Hb"
      },
      "outputs": [],
      "source": [
        "!python2 cidereval.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFhKdaL404Il"
      },
      "outputs": [],
      "source": [
        "file2 = open('./cider_' + name + '_results.json')\n",
        "cider_output = json.load(file2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDltrQ7e06av"
      },
      "outputs": [],
      "source": [
        "%cd ../spice/\n",
        "write_file = open(name + \"_meteor_refs\", \"w\")\n",
        "for i in range(len(cider_refs_thresholder)):\n",
        "  new_line = cider_refs_thresholder[i]['caption'].replace(\"\\n\", \" \") + \" \\n\"\n",
        "  write_file.write(new_line)\n",
        "write_file.close()\n",
        "\n",
        "write_file2 = open(name + \"_meteor_test\", \"w\")\n",
        "for i in range(len(cider_test_thresholder)):\n",
        "  if (cider_test_thresholder[i]['caption'] == \"\" or cider_test_thresholder[i]['caption'] == \" \"):\n",
        "    new_line = \"empty \\n\"\n",
        "  else:\n",
        "    new_line = cider_test_thresholder[i]['caption'].replace(\"\\n\", \" \") + \" \\n\"\n",
        "  write_file2.write(new_line)\n",
        "write_file2.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs6KhufQ087h"
      },
      "outputs": [],
      "source": [
        "meteor_scores = !java -Xmx2G -jar meteor-1.5.jar ./gpt2_raw_freeflow_output_meteor_test ./gpt2_raw_freeflow_output_meteor_refs -l en -norm -a data/paraphrase-en.gz -q\n",
        "meteor_scores = [float(meteor_scores[i]) for i in range(len(meteor_scores))]\n",
        "meteor_scores[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBM7npIk1EYK"
      },
      "outputs": [],
      "source": [
        "#in spice directory\n",
        "!java -Xmx8G -jar spice-1.0.jar spice_gpt2_raw_freeflow_output.json -cache ./cache2 -out spice_gpt2_raw_freeflow_output_output.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Khg9ENq1JrS"
      },
      "outputs": [],
      "source": [
        "file2 = open('./spice_' + name + '_output.json')\n",
        "spice_output = json.load(file2)\n",
        "len(spice_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhQRvm7e1N-u"
      },
      "outputs": [],
      "source": [
        "rouge_test =  [cider_test_thresholder[i]['caption'] for i in range(len(cider_test_thresholder))]\n",
        "rouge_refs =  [cider_refs_thresholder[i]['caption'] for i in range(len(cider_refs_thresholder))]\n",
        "r = Rouge()\n",
        "rouge_scores = r.compute_score(rouge_refs, rouge_test)\n",
        "rouge_scores[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBbdU42S1Pta"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "spice_predictions_array = []\n",
        "cider_predictions_array = []\n",
        "meteor_predictions_array = []\n",
        "rouge_predictions_array = []\n",
        "counter = []\n",
        "for k in range(len(spice_output)):\n",
        "  if (k % 500 == 0):\n",
        "    print(k)\n",
        "  # l1 = data[\"Gold\"][k]\n",
        "  # l2 = data[\"Output\"][k]\n",
        "  # if data[\"Correctness\"][k]:\n",
        "  #   positive_indices.append(k)\n",
        "  # else:\n",
        "  #   negative_indices.append(k)\n",
        "  spice_predictions_array.append(spice_output[k]['scores']['All']['f'])\n",
        "  cider_predictions_array.append(cider_output[\"CIDEr\"][k])\n",
        "  meteor_predictions_array.append(meteor_scores[k])\n",
        "  rouge_predictions_array.append(rouge_scores[1][k])\n",
        "\n",
        "# print(count)\n",
        "# print(len(counter))\n",
        "# # x = len(data[\"q_text\"])\n",
        "print(\"SPICE==============\")\n",
        "print(np.average(spice_predictions_array))\n",
        "print(\"CIDEr==============\")\n",
        "print(np.average(cider_predictions_array)/10)\n",
        "print(\"METEOR==============\")\n",
        "print(np.average(meteor_predictions_array))\n",
        "print(\"ROUGE==============\")\n",
        "print(np.average(rouge_predictions_array))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aatdVDDw1dpi"
      },
      "outputs": [],
      "source": [
        "sts_bert_output = [web_model.predict([(data['gold'][i], data['output'][i])])[0] for i in range(len(data['input']))]\n",
        "print(\"STS-BERT===========\")\n",
        "print(np.average(sts_bert_output)/5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "generation_eval.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GPT-2",
      "language": "python",
      "name": "gpt-2"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
